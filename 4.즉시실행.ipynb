{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNivewSQea9OQ02hSrkH01m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quastarK/Tensorflow_colab/blob/Tensorflow-2.0-%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88/4_%EC%A6%89%EC%8B%9C%EC%8B%A4%ED%96%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b3GAeTBk74fq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수는 객체\n",
        "\n",
        "즉시실행에서 변수는 그객체의 마지막 참조가 제거될때까지 유지되고 그 이후 삭제됨"
      ],
      "metadata": {
        "id": "C6nC2ojr8dR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"gpu:0\"):\n",
        "    print(\"GPU 사용 가능\")\n",
        "    v = tf.Variable(tf.random.normal([1000, 1000]))\n",
        "    v = None  # v는 더이상 GPU 메모리를 사용하지 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZk4dEr_8WmD",
        "outputId": "ac82e448-8c62-4ee2-b9dc-954c048ec8b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 사용 가능\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(v) #참조가 사라짐"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40gTYPNb8496",
        "outputId": "325fb69c-866f-448a-9cdb-ea25fde099f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 객체 기반의 저장\n",
        "\n",
        "모델의 상태를 저장할때 사용\n",
        "\n",
        "tf.train.Checkpoint는 tf.Variable을 체크포인트 파일로 저장하거나 체크포인트 파일에서 복구할 수 있음"
      ],
      "metadata": {
        "id": "baBo1xdQ9boo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(10.0)\n",
        "checkpoint = tf.train.Checkpoint(x=x)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak9232el8Ww1",
        "outputId": "43e973ff-a1c6-40fd-cafa-29309973bd1a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.assign(2.)\n",
        "checkpoint_path = './ckpt/'\n",
        "checkpoint.save('./ckpt/')  # -1 이라는 이름으로 저장 된것\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c14RUuou-Nf_",
        "outputId": "baeda5cf-6b9e-4fd6-e84a-9e60a8db3e1f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.assign(11.) # 저장한 후에 변수 변경\n",
        "print(x)\n",
        "# 체크포인트로부터 값을 복구 2로 저장되어 있었음\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaHEisz-8ZEG",
        "outputId": "33c53fcf-eff0-4f22-8cfd-1609263b24ba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=11.0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7b1742ce0e80>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h_gi3eB9EHo",
        "outputId": "c41f2fc9-1a97-4cc5-c4ae-487766322eb0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 동적인 제어 흐름\n",
        "\n",
        "모델을 저장하거나 읽어들이기 위해서 tf.train.Checkpoint는 숨겨진 변수를 요구하지 않고 객체 내부 상태를 저장합니다.\n",
        "\n",
        "옵티마이저와 모델, 전역 단계 상태를 기록하려면 tf.train.Checkpoint에 전달하면 된다."
      ],
      "metadata": {
        "id": "AnLTGs1A-m_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "checkpoint_dir = 'path/to/model_dir'\n",
        "if not os.path.exists(checkpoint_dir):      # 폴더가 없으면 폴더 생성\n",
        "  os.makedirs(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,     # Checkpoint에 model, optimizer 전달\n",
        "                           model=model)\n",
        "\n",
        "root.save(checkpoint_prefix)      # 저장 path/to/model_dir 안에 ckpt~ 이름으로 저장\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtIS7GGN9EdL",
        "outputId": "9c225c6f-cc42-4936-a400-af1d759ed237"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7b163d1ddc90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 객체 지향형 지표\n",
        "\n",
        "tf.keras.metrics는 객체로 저장됩니다.\n",
        "새로운 데이터를 이 객체에 전달하여 지표를 수정하고 tf.keras.metrics.result 메서드를 사용해 그 결과를 얻음"
      ],
      "metadata": {
        "id": "lZF9277z_r-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.keras.metrics.Mean('loss')"
      ],
      "metadata": {
        "id": "_4cInBOp9JPf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m(0)    # 0 값이 들어감\n",
        "m(5)  # 5 값이 들어감 -> [0,5]\n",
        "m.result() # mean([0,5]) = 2.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRruGGov9KtT",
        "outputId": "fb7240aa-e1d2-4edc-cd71-75ddbe12245d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.5>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m([8, 9]) # [0, 5, 8, 9]\n",
        "m.result()  #mean([0,5,8,9]) = 5.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-eRaa_f9PJN",
        "outputId": "22dd924c-6460-4c88-f6c8-4422558f2181"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=5.5>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 서머리 (summary)와 텐서 보드\n",
        "\n",
        "텐서보드는 훈련과정에서 모델을 파악하거나 디버깅하고 최적화하기 위해 사용하는 시각화 도구입니다.\n",
        "텐서보드는 프로그램이 실행되는 동안 작성된 서머리 이벤츠를 사용함\n",
        "\n",
        "\n",
        "즉시 실행에서 변수의 서머리 정보를 기록하기 위해서 tf.summary를 사용함\n",
        "예를 들어, 다음에 매 100번째 훈련마다 loss의 서머리 정보를 기록"
      ],
      "metadata": {
        "id": "vSGif7FKAV1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"./tb/\"\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "with writer.as_default():\n",
        "  for i in range(1000): # 또는 반복전에 writer.set_as_default()를 호출\n",
        "    step = i+1\n",
        "    # 실제 훈련 함수로 손실을 계산\n",
        "    loss = 1- 0.001*step\n",
        "    if step % 100 ==0:\n",
        "      tf.summary.scalar('손실',loss, step=step)"
      ],
      "metadata": {
        "id": "-cAg6raP9TuZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사용자 정의 그래디언트\n",
        "\n",
        "정방향 함숭란에서 입력값 or 출력값, 중간값과 관련된 그래디언트를 정의해야 함\n"
      ],
      "metadata": {
        "id": "Nm8LXeoMB617"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def clip_gradient_by_norm(x,norm):\n",
        "  y = tf.identity(x)\n",
        "  def grad_fn(dresult):\n",
        "    return [tf.clip_by_norm(dresult,norm), None]  # clip_by_norm : gradient가 너무 커져 모델의 학습이 이상해지는 것 막음 (loss의 최대 최소값 설정, clip)\n",
        "  return y, grad_fn"
      ],
      "metadata": {
        "id": "Jf4olBdkBE0z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 체크\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T2VaGfYNDnd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZuijO02DsPe",
        "outputId": "6d9ef98c-666e-4a7a-ffba-a52567653cf0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1706713602.4009411"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure(x, steps):\n",
        "  # 텐서플로는 처음 사용할 때 GPU를 초기화, 시간계산에서 제외\n",
        "  tf.matmul(x, x)\n",
        "  start = time.time()\n",
        "  for i in range(steps):\n",
        "    x = tf.matmul(x, x)\n",
        "  # tf.matmul는 행렬 곱셈을 완료하기 전에 결과를 반환할 수 있습니다\n",
        "  # (예, CUDA 스트림 대기열에 연산을 추가한 후에 결과를 반환할 수 있다).\n",
        "  # 아래 x.numpy() 호출은 대기열에 추가된 모든 연산이 완료될 것임을 보장합니다\n",
        "  # (그리고 그 결과가 호스트 메모리에 복사될 것이고,\n",
        "  # 그래서 matnul 연산시간보다는 조금 많은 연산시간이\n",
        "  # 포함됩니다).\n",
        "  _ = x.numpy()\n",
        "  end = time.time()\n",
        "  return end - start\n"
      ],
      "metadata": {
        "id": "Xy3uKAhQDtRr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "measure(tf.ones([1000,1000]), 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7uEczgzDu54",
        "outputId": "4fff8f73-edbd-41b3-8707-6923a0832119"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5183589458465576"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "print(\"{} 크기 행렬을 자기 자신과 {}번 곱했을 때 걸리는 시간:\".format(shape, steps))\n",
        "\n",
        "# CPU에서 실행:\n",
        "with tf.device(\"/cpu:0\"):\n",
        "  print(\"CPU: {} 초\".format(measure(tf.random.normal(shape), steps)))\n",
        "\n",
        "# GPU에서 실행, 가능하다면:\n",
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    print(\"GPU: {} 초\".format(measure(tf.random.normal(shape), steps)))\n",
        "else:\n",
        "  print(\"GPU: 없음\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8PKGWIcDwCe",
        "outputId": "87a16321-cc85-46a0-c1a3-a32d9f1a2f8a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 1000) 크기 행렬을 자기 자신과 200번 곱했을 때 걸리는 시간:\n",
            "CPU: 6.0387914180755615 초\n",
            "GPU: 0.15822887420654297 초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "  x = tf.random.normal([1000, 1000])\n",
        "\n",
        "  x_gpu0 = x.gpu()\n",
        "  x_cpu = x.cpu()\n",
        "\n",
        "  _ = tf.matmul(x_gpu0, x_gpu0)\n",
        "  _ = tf.matmul(x_cpu, x_cpu)"
      ],
      "metadata": {
        "id": "0Jm9F3ubD1rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit tf.matmul(x_gpu0, x_gpu0)"
      ],
      "metadata": {
        "id": "ugEpQT9AD5JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit tf.matmul(x_cpu, x_cpu)"
      ],
      "metadata": {
        "id": "GaSYXvXlD5SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j87AKez-D6-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
